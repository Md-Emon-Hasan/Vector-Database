{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, World!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "   Author  : Emon Hasan\n",
    "   Email   : iconicemon01@gmail.com\n",
    "   GitHub  : https://github.com/Md-Emon-Hasan\n",
    "   LinkedIn: https://www.linkedin.com/in/emon-hasan/\n",
    "   Date    : 01/28/2025\n",
    "   Time    : 18:48\n",
    "   Purpose : How Chorama DB works\n",
    "'''\n",
    "\n",
    "# Run and Check Compiler\n",
    "def main():\n",
    "    print('Hello, World!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)  # Should print 2.10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "from langchain.vectorstores import Chroma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector database\n",
    "from langchain.embeddings import HuggingFaceEmbeddings  # Open-source embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import HuggingFacePipeline  # Using FLAN-T5 for QA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import TextLoader  # Load text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter  # Split text into chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA  # Question-answering pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Program Files\\Python39\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline  # Hugging Face pipeline for FLAN-T5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document  # Required for metadata handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Download Example Dataset\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the dataset (collection of text files)\n",
    "url = \"https://www.dropbox.com/s/vs6ocyvpzzncvwh/new_articles.zip?dl=1\"\n",
    "response = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save it locally\n",
    "zip_path = \"new_articles.zip\"\n",
    "with open(zip_path, \"wb\") as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the ZIP file into a folder\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"new_articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Load Documents and Add Metadata (Fix for Missing Source)\n",
    "directory_path = \"new_articles\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all text files and store them as Document objects with metadata\n",
    "documents = []\n",
    "for file_name in os.listdir(directory_path):\n",
    "    if file_name.endswith('.txt'):  # Process only text files\n",
    "        file_path = os.path.join(directory_path, file_name)\n",
    "        \n",
    "        try:\n",
    "            with open(file_path, encoding='utf-8') as f:\n",
    "                content = f.read()\n",
    "        except UnicodeDecodeError:\n",
    "            with open(file_path, encoding='latin-1') as f:\n",
    "                content = f.read()\n",
    "\n",
    "        # Create a Document object with metadata (filename as 'source')\n",
    "        doc = Document(page_content=content, metadata={\"source\": file_name})\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 21 documents.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Successfully loaded {len(documents)} documents.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split Documents into Smaller Chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "split_texts = text_splitter.split_documents(documents)  # Now retains metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Chunks Created: 233\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Chunks Created: {len(split_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Initialize Embeddings Model\n",
    "embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create ChromaDB Vector Store\n",
    "persist_directory = \"db\"  # Directory to store the database\n",
    "vectordb = Chroma.from_documents(documents=split_texts, embedding=embedding, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Persist the database to disk\n",
    "vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Reload Vector Database\n",
    "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Create a Retriever (Top 2 Most Relevant Chunks)\n",
    "retriever = vectordb.as_retriever(search_kwargs={\"k\": 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Load the FLAN-T5 Model for Question Answering\n",
    "flan_t5_pipeline = pipeline(\"text2text-generation\", model=\"google/flan-t5-base\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap the model for LangChain\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=flan_t5_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10: Create a Question-Answering (QA) Chain\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11: Function to Process and Display Answers (Fix for Missing Source)\n",
    "def process_llm_response(llm_response):\n",
    "    print(\"AI Answer:\", llm_response['result'])\n",
    "    \n",
    "    print(\"\\n\\nSources:\")\n",
    "    if \"source_documents\" in llm_response:\n",
    "        for source in llm_response[\"source_documents\"]:\n",
    "            # Ensure 'source' key exists in metadata before accessing it\n",
    "            if \"source\" in source.metadata:\n",
    "                print(f\"- {source.metadata['source']}\")\n",
    "            else:\n",
    "                print(\"- [No source available]\")  # Handle missing metadata gracefully\n",
    "    else:\n",
    "        print(\"- [No source documents found]\")  # Handle missing source_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Answer: $10 billion\n",
      "\n",
      "\n",
      "Sources:\n",
      "- [No source available]\n",
      "- 05-03-chatgpt-everything-you-need-to-know-about-the-ai-powered-chatbot.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Ask a Question and Get an Answer\n",
    "query = \"How much money did Microsoft raise?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Answer: yes\n",
      "\n",
      "\n",
      "Sources:\n",
      "- 05-04-microsoft-doubles-down-on-ai-with-new-bing-features.txt\n",
      "- [No source available]\n"
     ]
    }
   ],
   "source": [
    "# break it down\n",
    "query = \"any news for microsoft?\"\n",
    "llm_response = qa_chain(query)\n",
    "process_llm_response(llm_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleteing the DB\n",
    "\n",
    "# !zip -r db.zip ./db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To cleanup, you can delete the collection\n",
    "# vectordb.delete_collection()\n",
    "# vectordb.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete the directory\n",
    "# !rm -rf db/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
